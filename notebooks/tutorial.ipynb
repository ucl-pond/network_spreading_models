{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from src.network_diffusion_model import NDM\n",
    "from src.FKPP_model import FKPP\n",
    "from src.find_optimal_timepoint import find_optimal_timepoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will load in some key files: the reference list and the connectome. The reference list should contain labels for each node in the connectome, in the same order as they appear in the connectome matrix. These files are all we need to simulate pathology spread using network spreading models.\n",
    "\n",
    "The region names in the reference list should be in the format: \"region_L\" or \"region_R\", where \"L\" and \"R\" denote left and right hemispheres, respectively.\n",
    "\n",
    "Let's look at the example files in \"tutorial_data\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the connectome\n",
    "connectome_fname = \"tutorial_data/tractography.csv\"\n",
    "connectome = pd.read_csv(connectome_fname, header=None).values\n",
    "\n",
    "# load in the reference list\n",
    "ref_list_df = pd.read_csv(\"tutorial_data/RegionList.csv\")\n",
    "ref_list = ref_list_df.region_name.to_list() # needs to be converted to a list\n",
    "print(ref_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can check that the number of regions in the connectome matches the number of regions in the reference list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(connectome.shape[0] == len(ref_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialising the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by running the network diffusion model with the example data. First we need to set the time points for which we want to simulate pathology spread. Here we will simulate from time 0 to 25 in 1000 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0,25,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will set up our model, using the connectome file and reference list we loaded earlier.\n",
    "\n",
    "We set gamma, the spreading parameter, to 1 here. Since we are modelling on an arbitrary timescale the value of gamma doesn't matter. We also set the seed region to \"Entorhinal\", meaning that pathology will be initialised at a value of 1 in both the left and right entorhinal cortices, and 0 elsewhere.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndm = NDM(connectome_fname,\n",
    "          gamma=1,\n",
    "          t=t,\n",
    "          ref_list=ref_list,\n",
    "          seed_region = \"Entorhinal\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simulate pathology spread using the `run_NDM` method. We can check the size of the output, it should be the number of brain regions by the number of time points we specified earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ndm.run_NDM()\n",
    "\n",
    "print(output.shape) # n_regions x n_timepoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the output\n",
    "\n",
    "We can visualise the simulated pathology spread over time using the `plot_time_series` function. This will plot the predicted pathology accumulation over time for each brain region, with different colours for each region. It is important to check that the time points extend far enough for the pathology to reach a steady state across the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plot_functions import plot_times_series\n",
    "\n",
    "plot_times_series(output, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same for the FKPP model. This is similar to the NDM, but contains an additional term that simulates local production of pathology in each region.\n",
    "\n",
    "The balance between spreading and local production is controlled by the alpha parameter. Here we set alpha to 0.5, meaning that spreading and local production contribute equally to pathology accumulation. We also set gamma to 1 as before, and use the same time points and seed region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fkpp = FKPP(connectome_fname,\n",
    "            alpha=0.5,\n",
    "            gamma=1,\n",
    "            t=t,\n",
    "            ref_list=ref_list,\n",
    "            seed_region = \"Entorhinal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_fkpp = fkpp.run_FKPP()\n",
    "\n",
    "plot_times_series(output_fkpp, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try adjusting the alpha parameter and the seed region to see how this affects the spread dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model to some target data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, we want to fit the model to some empirical data, for example regional pathology measurements from patients. We can then examine the optimal parameters that provide the best fit to our data. \n",
    "Here we will load in some example target data and fit the model to this data. The target data comes from tau PET measurements, averaged across patients on the Alzheimer's disease spectrum.\n",
    "\n",
    "It is important to check that the ordering of the regions in the target data matches those in the reference list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tutorial_data/pathology.csv\", names=['region','pathology'], header=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to extract the pathology values and normalise them to a range of 0 to 1 for fitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pathology = df['pathology'].values\n",
    "target_pathology = (target_pathology - target_pathology.min()) / (target_pathology.max() - target_pathology.min())\n",
    "target_pathology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our target pathology data ready for fitting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the network diffusion \n",
    "For the NDM model, we simply find the seed region that provides the best fit to the target data. The `optimise_seed_region` method returns the sum-of-squared-errors (SSE) between the model output and target data for each seed region, as well as the optimal seed that gives the lowest SSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, optimal_params = ndm.optimise_seed_region(target_data=target_pathology)\n",
    "\n",
    "print(\"optimal seed region\", optimal_params, \"\\n\")\n",
    "\n",
    "print(res.sort_values(by='SSE').head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the seeds that provide the best fit to the data are mostly in the temporal lobe, as we would expect.\n",
    "\n",
    "Now we can run the model again using the optimal seed region to visualise the fit to the data.\n",
    "\n",
    "The `find_optimal_timepoint` function finds the time point at which the model output best fits the target data, returning the index of this time point, the predicted pathology values at this time point, and the corresponding SSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndm = NDM(connectome_fname,\n",
    "          gamma=1,\n",
    "          t=t,\n",
    "          ref_list=ref_list,\n",
    "          seed_region = optimal_params['seed'])\n",
    "\n",
    "ndm_output = ndm.run_NDM()\n",
    "min_idx, ndm_prediction, SSE = find_optimal_timepoint(ndm_output, target_pathology)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the predicted pathology values against the target data at this optimal time point. You could also use a package like ggseg to visualise the spatial distribution of pathology across the brain regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(target_pathology, ndm_prediction)\n",
    "plt.xlabel(\"Target Pathology\")\n",
    "plt.ylabel(\"Model Prediction\")\n",
    "plt.title(\"NDM Model Fit to Target Pathology\")\n",
    "\n",
    "print(\"correlation between model prediction and pathology = \", np.corrcoef(target_pathology, ndm_prediction)[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the FKPP model\n",
    "\n",
    "The `optimise_fkpp_params` method optimises both the seed region and the alpha parameter for the FKPP model. It returns the optimal parameters that provide the best fit to the target data. This takes a little longer to run since it needs to optimise alpha for each seed region, but should only take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fkpp = FKPP(connectome_fname,\n",
    "            gamma=1,\n",
    "            t=t,\n",
    "            ref_list=ref_list)\n",
    "res, optimal_params = fkpp.optimise_fkpp_params(target_data=target_pathology)\n",
    "\n",
    "print(\"optimal parameters\", optimal_params, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can run the optimised model to get the predicted pathology values at the optimal time point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fkpp = FKPP(connectome_fname,\n",
    "            alpha=optimal_params['alpha'],\n",
    "            gamma=1,\n",
    "            t=t,\n",
    "            ref_list=ref_list,\n",
    "            seed_region = optimal_params['seed'])\n",
    "\n",
    "fkpp_output = fkpp.run_FKPP()\n",
    "min_idx, fkpp_prediction, SSE = find_optimal_timepoint(fkpp_output, target_pathology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(target_pathology, fkpp_prediction)\n",
    "plt.xlabel(\"Target Pathology\")\n",
    "plt.ylabel(\"Model Prediction\")\n",
    "plt.title(\"FKPP Model Fit to Target Pathology\")\n",
    "\n",
    "print(\"correlation between model prediction and pathology = \", np.corrcoef(target_pathology, fkpp_prediction)[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted FKPP model\n",
    "The third model in the toolbox is the weighted-FKPP, which extends the FKPP by allowing for different rates of pathology production in each brain region. This allows us to model regional variations in pathology vulnerability across the brain. We can use this model to test hypotheses about different factors that may influence pathology production, such as gene expression or connectivity properties.\n",
    "\n",
    "In practise, it is very similar to running the FKPP model, but we need to provide a `weights` array that contains the relative production rates for each brain region. In this example we will use regional amyloid-PET values as weights, since amyloid pathology is thought to influence tau pathology production in Alzheimer's disease. We can test whether including these weights improves the model fit to the target tau-PET data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amyloid = pd.read_csv(\"tutorial_data/regional_amyloid.csv\", names=['region','amyloid'], header=0)\n",
    "\n",
    "weighted_fkpp = FKPP(connectome_fname,\n",
    "            gamma=1,\n",
    "            t=t,\n",
    "            ref_list=ref_list,\n",
    "            weights=amyloid['amyloid'].values)\n",
    "\n",
    "res, optimal_params = weighted_fkpp.optimise_fkpp_params(target_data=target_pathology)\n",
    "\n",
    "print(\"optimal parameters\", optimal_params, \"\\n\")\n",
    "\n",
    "optimal_weighted_fkpp = FKPP(connectome_fname,\n",
    "            alpha=optimal_params['alpha'],\n",
    "            gamma=1,\n",
    "            t=t,\n",
    "            ref_list=ref_list,\n",
    "            weights=amyloid['amyloid'].values,\n",
    "            seed_region = optimal_params['seed'])\n",
    "\n",
    "optimal_weighted_fkpp_output = optimal_weighted_fkpp.run_FKPP()\n",
    "min_idx, weighted_fkpp_prediction, SSE = find_optimal_timepoint(optimal_weighted_fkpp_output, target_pathology)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(target_pathology, weighted_fkpp_prediction)\n",
    "plt.xlabel(\"Target Pathology\")\n",
    "plt.ylabel(\"Model Prediction\")\n",
    "plt.title(\"weighted FKPP Model Fit to Target Pathology\")\n",
    "\n",
    "print(\"correlation between model prediction and pathology = \", np.corrcoef(target_pathology, weighted_fkpp_prediction)[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the ModelSelection class to compare the two models based on their residuals. Here we use the corrected Akaike Information Criterion (AICc) to compare the NDM and FKPP models. The model with the lower AICc value is considered to have a better fit to the data, taking into account the number of parameters in each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ModelSelection import ModelSelection\n",
    "\n",
    "# calculate the residuals for each model, needs to be sized (n_obs, n_models)\n",
    "residuals = np.array([target_pathology - ndm_prediction,\n",
    "                        target_pathology - fkpp_prediction,\n",
    "                        target_pathology - weighted_fkpp_prediction]).T\n",
    "\n",
    "# the FKPP has 3 parameters (alpha, seed, time), NDM has 2 (seed, time)\n",
    "results = ModelSelection(n_dof=[2,3,3], criterion=\"AICc\", model_names=[\"NDM\", \"FKPP\", \"weighted-FKPP\"])(residuals)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from these results that the weighted-FKPP model has a lower AICc value, indicating that it provides a better fit to the target pathology data compared to the NDM model. This suggests that weighting pathology production in the model by amyloid burden improves its ability to capture the observed patterns of pathology accumulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other features\n",
    "\n",
    "TODO: add sections on:\n",
    "- cortical_idx\n",
    "- lateral seeding\n",
    "- x0 initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "network_spreading_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
